{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268b68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1e8784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0    X2         X3  X4        X5         X6     Y\n",
       "0   1  32.0   84.87882  10  24.98298  121.54024  37.9\n",
       "1   2  19.5  306.59470   9  24.98034  121.53951  42.2\n",
       "2   3  13.3  561.98450   5  24.98746  121.54391  47.3\n",
       "3   4  13.3  561.98450   5  24.98746  121.54391  54.8\n",
       "4   5   5.0  390.56840   5  24.97937  121.54245  43.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data=pd.read_csv(\"03_realestate_dataset.csv\",delimiter=\";\",decimal=\",\")\n",
    "raw_data.columns=['X0','X1','X2','X3','X4','X5','X6','Y']\n",
    "raw_data=raw_data.drop(['X1'], axis=1)\n",
    "raw_data.head(5)\n",
    "#raw_data.dtypes\n",
    "\n",
    "#isinstance(data, pd.DataFrame)\n",
    "#raw_data.shape\n",
    "#list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a9c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold_value=None, left_child=None, right_child=None, variance_reduction=None, value=None):\n",
    "        self.feature_index=feature_index\n",
    "        self.threshold_value=threshold_value\n",
    "        self.left_child=left_child\n",
    "        self.right_child=right_child\n",
    "        self.variance_reduction=variance_reduction\n",
    "        self.value=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047e0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class RegressionTree():\n",
    "    def __init__(self,min_samples_in_split=2,max_tree_depth=2):  # for the stopping criteria to avoid overfitting problem\n",
    "        self.root=None \n",
    "        self.min_samples_in_split=min_samples_in_split\n",
    "        self.max_tree_depth=max_tree_depth\n",
    "        \n",
    "        \n",
    "        \n",
    "    def variance_reduction(self,parent_node,left_child,right_child):\n",
    "        weight_left_child=len(left_child)/len(parent_node) # is used for scaling\n",
    "        weight_right_child=len(right_child)/len(parent_node)\n",
    "        variance_reduction=np.var(parent_node) - (weight_left_child*np.var(left_child) + weight_right_child*np.var(right_child))  \n",
    "        return variance_reduction\n",
    "            \n",
    "    \n",
    "#define the tree building method\n",
    " \n",
    "    def build_tree(self,dataset,current_depth=0):\n",
    "        X,Y = dataset[:,:-1], dataset[:,-1]  #seperate the variables from the target variable\n",
    "        num_samples,num_features=np.shape(X)\n",
    "        best_split_pool={}\n",
    "        if num_samples>=self.min_samples_in_split and current_depth<=self.max_tree_depth:\n",
    "            best_split_pool=self.find_best_split(dataset,num_samples,num_features)\n",
    "            if best_split_pool[\"variance_reduction\"]>0: \n",
    "                left_subtree=self.build_tree(best_split_pool[\"left_data\"],current_depth+1)\n",
    "                right_subtree=self.build_tree(best_split_pool[\"right_data\"],current_depth+1)\n",
    "                \n",
    "                #create the decision node\n",
    "                return Node(best_split_pool[\"feature_index\"],best_split_pool[\"threshold_value\"], left_subtree,right_subtree,best_split_pool[\"variance_reduction\"])\n",
    "\n",
    "        \n",
    "        leaf_value=self.leaf_node_value(Y) #  we use the calculate_leaf_value function to calculate leaf node value\n",
    "        return Node(value=leaf_value)   \n",
    "    \n",
    "    def split(self, dataset,feature_index, threshold_value):\n",
    "        left_data= np.array([row for row in dataset if row[feature_index]<=threshold_value])\n",
    "        right_data= np.array([row for row in dataset if row[feature_index]>threshold_value])\n",
    "        return left_data, right_data\n",
    "    \n",
    "    \n",
    "    def find_best_split(self,dataset,num_samples,num_features):\n",
    "        best_split_pool={} \n",
    "        max_variance_reduction=-float(\"inf\")\n",
    "        \n",
    "        for feature_index in range(num_features): #loop through all features and all possible threshold values for that feature\n",
    "            feature_values=dataset[:,feature_index]\n",
    "            possible_thresholds=np.unique(feature_values)  \n",
    "            \n",
    "            for threshold_value in possible_thresholds:\n",
    "                left_data, right_data=self.split(dataset, feature_index,threshold_value)\n",
    "                if len(left_data)>0 and len(right_data)>0: \n",
    "                    Y,left_Y,right_Y=dataset[:,-1], left_data[:,-1],right_data[:,-1] \n",
    "                    curr_variance_reduction=self.variance_reduction(Y,left_Y,right_Y)  #to calculate the IG or reduction in impurity, use variance reduction\n",
    "                    \n",
    "                    if curr_variance_reduction>max_variance_reduction: # if this IG is greater than the max IG then update best split \n",
    "                        best_split_pool[\"feature_index\"]=feature_index\n",
    "                        best_split_pool[\"threshold_value\"]=threshold_value\n",
    "                        best_split_pool[\"left_data\"]=left_data\n",
    "                        best_split_pool[\"right_data\"]=right_data\n",
    "                        best_split_pool[\"variance_reduction\"]=curr_variance_reduction\n",
    "                        max_variance_reduction=curr_variance_reduction\n",
    "                    \n",
    "        return best_split_pool\n",
    "    \n",
    "    \n",
    "    def leaf_node_value(self,Y):\n",
    "        leaf_val=np.mean(Y)\n",
    "        return leaf_val\n",
    "    \n",
    "\n",
    "    #to print the decision tree     \n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree=self.root\n",
    "            \n",
    "        \n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "            \n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold_value, \"?\", tree.variance_reduction)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left_child, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right_child, indent +  indent)\n",
    "            \n",
    "    \n",
    "    def fit(self, X,Y):\n",
    "        \n",
    "        dataset=np.concatenate((X,Y), axis=1)\n",
    "        self.root= self.build_tree(dataset)  #build the tree to train the model\n",
    "        \n",
    "    \n",
    "    def make_prediction(self,x,tree): # take a single data point and find the corresponding y value\n",
    "        # start with root node, if it meets the conditions, then it goes to left child else moves to the right node. repeat \n",
    "        # till you reach to the leaf node\n",
    "        \n",
    "        if tree.value!=None: \n",
    "            return tree.value\n",
    "        feature_val=x[tree.feature_index]\n",
    "        if feature_val<= tree.threshold_value:\n",
    "            return self.make_prediction(x,tree.left_child)\n",
    "        else:\n",
    "            return self.make_prediction(x,tree.right_child)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        predictions=[self.make_prediction(x,self.root) for x in X]\n",
    "        return predictions  #an array of target values\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c0eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training and test split\n",
    "\n",
    "X=raw_data.iloc[:,:-1].values\n",
    "Y= raw_data.iloc[:,-1].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.20, random_state=41)\n",
    "\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873a3402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 967.4 ? 82.36533475987822\n",
      " left:X_1 <= 8.5 ? 20.92490340212737\n",
      "  left:X_2 <= 383.8624 ? 8.604444444444454\n",
      "    left:X_5 <= 121.54102 ? 12.12001851851852\n",
      "        left:49.98666666666668\n",
      "        right:57.17777777777778\n",
      "    right:X_2 <= 577.9615 ? 8.712\n",
      "        left:46.67\n",
      "        right:38.75\n",
      "  right:X_2 <= 330.0854 ? 12.728022081608842\n",
      "    left:X_5 <= 121.54026 ? 22.64988587104476\n",
      "        left:39.07058823529412\n",
      "        right:49.266666666666666\n",
      "    right:X_4 <= 24.96398 ? 9.182353578336553\n",
      "        left:29.581818181818186\n",
      "        right:39.47659574468085\n",
      " right:X_5 <= 121.51046 ? 16.877603697493974\n",
      "  left:X_1 <= 18.0 ? 2.0310443333100174\n",
      "    left:X_0 <= 330.0 ? 2.5986170703575544\n",
      "        left:17.05333333333333\n",
      "        right:12.05\n",
      "    right:X_2 <= 4136.271 ? 4.55013888888889\n",
      "        left:22.375\n",
      "        right:17.85\n",
      "  right:X_4 <= 24.9832 ? 13.405732981548788\n",
      "    left:X_1 <= 21.7 ? 8.801822909685551\n",
      "        left:26.82857142857143\n",
      "        right:18.2\n",
      "    right:X_3 <= 0.0 ? 40.833333333333336\n",
      "        left:43.5\n",
      "        right:30.666666666666668\n"
     ]
    }
   ],
   "source": [
    "# now fit the model\n",
    "\n",
    "regressor= RegressionTree(min_samples_in_split=3,max_tree_depth=3)\n",
    "regressor.fit(X_train,Y_train)\n",
    "regressor.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52113456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.877171469733579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model by calculating MSE\n",
    "Y_pred=regressor.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb570a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
